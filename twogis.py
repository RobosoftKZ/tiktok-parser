from lxml.etree import ElementTree
from lxml.html import fromstring
from playwright.async_api import async_playwright


async def find_xpath_by_href(page, href_substring: str = "/tab/reviews") -> str:
    locator = page.locator(f'a[href*="{href_substring}"]')

    try:
        await locator.first.wait_for(state="visible", timeout=10000)
        print("‚úÖ –°—Å—ã–ª–∫–∞ –Ω–∞–π–¥–µ–Ω–∞")
    except:
        print("‚ùå –°—Å—ã–ª–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return ""

    full_html = await page.content()
    doc = fromstring(full_html)
    tree = ElementTree(doc)

    for el in doc.xpath(f'//a[contains(@href, "{href_substring}")]'):
        xpath = tree.getpath(el)
        print(f"üìç XPATH –Ω–∞–π–¥–µ–Ω: {xpath}")
        return xpath

    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å XPATH")
    return ""


async def click_by_xpath(page, xpath: str):
    try:
        locator = page.locator(f'xpath={xpath}')
        await locator.scroll_into_view_if_needed()
        await locator.click()
        print("üñ±Ô∏è –ö–ª–∏–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∏–∫–µ: {e}")


async def find_load_more_button(page, button_text="–ó–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë"):
    locator = page.locator("button", has_text=button_text)

    if await locator.count() == 0:
        print("‚ùå –ö–Ω–æ–ø–∫–∞ '–ó–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return None

    print("‚úÖ –ö–Ω–æ–ø–∫–∞ '–ó–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë' –Ω–∞–π–¥–µ–Ω–∞")
    return locator.first


async def get_parent_class_by_text(page, text: str, levels_up: int = 8) -> str:
    locator = page.locator(f"text={text}")
    if await locator.count() == 0:
        print(f"‚ùå –≠–ª–µ–º–µ–Ω—Ç —Å —Ç–µ–∫—Å—Ç–æ–º '{text}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return ""

    element = await locator.first.element_handle()

    class_name = await element.evaluate(f'''(el) => {{
        let parent = el;
        for (let i = 0; i < {levels_up}; i++) {{
            if (!parent.parentElement) break;
            parent = parent.parentElement;
        }}
        return parent.className;
    }}''')

    print(f"‚úÖ –ö–ª–∞—Å—Å {levels_up}-–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è: {class_name}")
    return class_name


async def get_parent_class_by_text(page, text: str, levels_up: int = 8, timeout: int = 10000) -> str | None:
    try:
        await page.locator(f"text={text}").first.wait_for(timeout=timeout)
        print(f"‚úÖ –≠–ª–µ–º–µ–Ω—Ç '{text}' –ø–æ—è–≤–∏–ª—Å—è")
    except:
        print(f"‚ùå –≠–ª–µ–º–µ–Ω—Ç —Å —Ç–µ–∫—Å—Ç–æ–º '{text}' –Ω–µ –ø–æ—è–≤–∏–ª—Å—è –∑–∞ {timeout} –º—Å")
        return None

    element = await page.locator(f"text={text}").first.element_handle()
    if not element:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å element_handle()")
        return None

    class_name = await element.evaluate(f'''(el) => {{
        let parent = el;
        for (let i = 0; i < {levels_up}; i++) {{
            if (!parent.parentElement) break;
            parent = parent.parentElement;
        }}
        return parent.className;
    }}''')

    print(f"üì¶ –ö–ª–∞—Å—Å —Ä–æ–¥–∏—Ç–µ–ª—è –Ω–∞ {levels_up} —É—Ä–æ–≤–Ω–µ: {class_name}")
    return class_name


async def parse_reviews_by_container_class(page, container_class: str, max_count: int | None = None) -> list[dict]:
    reviews = page.locator(f'div.{container_class}')
    count = await reviews.count()
    print(f"üîé –ù–∞–π–¥–µ–Ω–æ {count} –æ—Ç–∑—ã–≤–æ–≤ —Å –∫–ª–∞—Å—Å–æ–º '{container_class}'")

    if max_count is not None:
        count = min(count, max_count)

    result = []
    for i in range(count):
        block = reviews.nth(i)

        # –ê–≤—Ç–æ—Ä
        author = await block.locator('._16s5yj36').first.get_attribute('title') or ""

        # –î–∞—Ç–∞
        date = await block.locator('._a5f6uz').first.text_content() or ""
        date = parse_russian_date(date)

        # –¢–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ
        text = ""
        text_locator = block.locator('a._1msln3t, a._1wlx08h')  # –æ–±–∞ –∫–ª–∞—Å—Å–∞ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        if await text_locator.count() > 0:
            text = await text_locator.first.text_content() or ""

        # –û—Ü–µ–Ω–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∂—ë–ª—Ç—ã—Ö –∑–≤—ë–∑–¥
        stars = await block.locator('._1fkin5c svg[fill="#ffb81c"]').count()

        # –û—Ç–≤–µ—Ç –æ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ ‚Äî –µ—Å–ª–∏ –µ—Å—Ç—å
        reply_locator = block.locator('._1wk3bjs')
        reply = await reply_locator.first.text_content() if await reply_locator.count() > 0 else None

        # –õ–∞–π–∫–∏ ‚Äî –µ—Å–ª–∏ –µ—Å—Ç—å
        likes = 0
        likes_locator = block.locator('._11fxohc span')
        if await likes_locator.count() > 0:
            likes_text = await likes_locator.first.text_content()
            if likes_text and likes_text.strip().isdigit():
                likes = int(likes_text.strip())

        result.append({
            "author": author.strip(),
            "date": date.strip(),
            "content": text.strip(),
            "stars": stars,
            "reply": reply.strip() if reply else None,
            "likes": likes,
            "url": "https://2gis.kz/reviews/70000001066969314"

        })

    return result


async def load_all_reviews_until_no_more_button(page, container_class: str, button_locator):
    previous_count = 0

    while True:
        current_count = await page.locator(f'div.{container_class}').count()

        if button_locator is None or await button_locator.count() == 0:
            print("üõë –ö–Ω–æ–ø–∫–∞ '–ó–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            break

        if current_count == previous_count:
            print("üü° –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ, –≤—Å—ë –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
            break

        previous_count = current_count

        try:
            await button_locator.click(force=True)
            print("üñ±Ô∏è –ö–Ω–æ–ø–∫–∞ '–ó–∞–≥—Ä—É–∑–∏—Ç—å –µ—â—ë' –Ω–∞–∂–∞—Ç–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∏–∫–µ –ø–æ –∫–Ω–æ–ø–∫–µ: {e}")
            break

        await page.wait_for_timeout(2000)


async def main(url: str) -> str:
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()
        await page.goto(url)
        print("üåê –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        xpath_for_href = await find_xpath_by_href(page, "/tab/reviews")
        await click_by_xpath(page, xpath_for_href)

        container_class = await get_parent_class_by_text(page, "–ü–æ–ª–µ–∑–Ω–æ?", levels_up=8)
        more_button_class = await find_load_more_button(page)
        await load_all_reviews_until_no_more_button(page, container_class, more_button_class)

        if container_class:
            reviews = await parse_reviews_by_container_class(page, container_class)
            save_reviews_to_json(reviews)
            for idx, r in enumerate(reviews, 1):
                print(f"\nüì¶ –û—Ç–∑—ã–≤ #{idx}")
                for k, v in r.items():
                    print(f"{k}: {v}")


import asyncio
import json

MONTHS_RU = {
    "—è–Ω–≤–∞—Ä—è": "01", "—Ñ–µ–≤—Ä–∞–ª—è": "02", "–º–∞—Ä—Ç–∞": "03", "–∞–ø—Ä–µ–ª—è": "04",
    "–º–∞—è": "05", "–∏—é–Ω—è": "06", "–∏—é–ª—è": "07", "–∞–≤–≥—É—Å—Ç–∞": "08",
    "—Å–µ–Ω—Ç—è–±—Ä—è": "09", "–æ–∫—Ç—è–±—Ä—è": "10", "–Ω–æ—è–±—Ä—è": "11", "–¥–µ–∫–∞–±—Ä—è": "12"
}


def parse_russian_date(date_str: str) -> str:
    # –£–¥–∞–ª—è–µ–º –∑–∞–ø—è—Ç—É—é –∏ "–æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω"
    cleaned = date_str.replace(", –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω", "").strip()

    # –†–∞–∑–±–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É
    parts = cleaned.split()
    if len(parts) != 3:
        return None

    day, month_rus, year = parts
    month = MONTHS_RU.get(month_rus.lower())

    if not month:
        return None

    return f"{year}-{month.zfill(2)}-{day.zfill(2)}"


def save_reviews_to_json(reviews: list[dict], filename: str = "reviews.json"):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(reviews, f, ensure_ascii=False, indent=2)
    print(f"üíæ –û—Ç–∑—ã–≤—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

if __name__ == "__main__":
    url = "https://2gis.kz/almaty/search/Top%20Tier/page/1/firm/70000001066969314/57.19912,50.280214?m=65.495135,44.841596/6.35"
    xpath = asyncio.run(main(url))
    print(f"üìç XPATH —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ—Ç–∑—ã–≤—ã: {xpath}")
